{% load static %}
<html>
<head>
<body onload="onLoad()">
<div id="container">
    <div id="show-background">Show background as magenta<input id="show-background-toggle" type="checkbox" checked></div>
    <canvas id="canvas" width=640px height=480px></canvas>
</div>
</body>
</head>
{#<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.2"> </script>#}
{#<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.2/dist/tf.min.js"></script>#}
<script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/1.5.1/tf.min.js"></script>
<script>
    async function onLoad() {
        {#const MODEL_URL = 'deeplabv3_mnv2_pascal_train_aug_web_model/frozen_inference_graph.pb';#}
        const MODEL_URL = '{% static 'model/frozen_inference_graph.pb' %}';
        {#const WEIGHTS_URL = 'deeplabv3_mnv2_pascal_train_aug_web_model/model.json';#}
        const WEIGHTS_URL = "{% static 'model/model.json' %}";
        // Model's input and output have width and height of 513.
        const TENSOR_EDGE = 513;
        const [model, stream] = await Promise.all([ tf.loadGraphModel(WEIGHTS_URL),
            navigator.mediaDevices.getUserMedia({video: {facingMode: 'user',
                    frameRate: 30, width : 320, height:240}})]);
        const video = document.createElement('video');
        video.autoplay = true;
        video.width = video.height = TENSOR_EDGE;
        const ctx = document.getElementById("canvas").getContext("2d");
        const videoCopy = ctx.canvas.cloneNode(false).getContext("2d");
        const maskContext = document.createElement('canvas').getContext("2d");
        maskContext.canvas.width = maskContext.canvas.height = TENSOR_EDGE;
        const img = maskContext.createImageData(TENSOR_EDGE, TENSOR_EDGE);
        let imgd = img.data;
        new Uint32Array(imgd.buffer).fill(0x00FFFF00);
        const render = () => {
            const t1 = performance.now();
            videoCopy.drawImage(video, 0, 0, ctx.canvas.width, ctx.canvas.height);
            const out = tf.tidy(() => {
                return model.execute({'ImageTensor': tf.browser.fromPixels(video).expandDims(0)});
            });
            const t2 = performance.now();
            const data = out.dataSync();
            const t3 = performance.now();
            for (let i = 0; i < data.length; i++) {
                imgd[i * 4 + 3] = data[i] == 15 ? 0 : 255;
            }
            maskContext.putImageData(img, 0, 0);
            ctx.drawImage(videoCopy.canvas, 0, 0);
            if (document.getElementById("show-background-toggle").checked)
                ctx.drawImage(maskContext.canvas, 0, 0, ctx.canvas.width, ctx.canvas.height);
            console.log("model.execute took " + (t2 - t1) + "ms, read data took " + (t3 - t2) + "ms, draw: " + (performance.now() - t3) + "ms.");
            window.requestAnimationFrame(render);
        }
        video.oncanplay = render;
        video.srcObject = stream;
    }
</script>
<style type="text/css">
    #container {
        position: relative;
        display: inline-block;
    }
    #show-background {
        position: absolute;
        bottom: 20px;
        right: 20px;
        color: gray;
        z-index: 5;
        height: 20px;
        text-align: right;
        display:block;
    }
    #show-background-toggle {
        height: 15px !important;
        vertical-align:middle;
    }
</style>
</html>



